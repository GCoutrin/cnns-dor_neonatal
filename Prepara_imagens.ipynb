{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"mount_file_id":"1AoQOuPvNWgZkbiDsi8XtB8kbgukyKS5N","authorship_tag":"ABX9TyNU2NYxdpdpqviqeoq5qnWD"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Introdução"],"metadata":{"id":"b0jW7VU76_EC"}},{"cell_type":"markdown","source":["Este notebook apresenta um conjunto de códigos desenvolvidos para o pré-processamento e organização da banco de imagens utilizado.\n","\n","Tópicos abordados:\n","\n","* **Detecção facial:** aplicação do modelo RetinaFace para extração das faces das imagens;\n","* **Leave-some-subjects-out:** protocolo de divisão de dados em treinamento e teste, considerando um processo de validação cruzada;\n","* **Data Augmentation:** criação de novas amostras para aumento do conjunto de dados para treinamento. As novas amostras são validadas pelo RetinaFace para garantir que a face humana não foi descaracterizada;\n","* **Divisão \"Dor\" e \"Sem_dor\"**: rotina desenvolvida para separar as imagens de cada indivíduo nas classes mencionadas."],"metadata":{"id":"jsqgiFyD7BpM"}},{"cell_type":"markdown","source":["# Configuração"],"metadata":{"id":"Vmtr5mDq8WKi"}},{"cell_type":"markdown","source":["### Bibliotecas"],"metadata":{"id":"3U0NdBuJJEUy"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"G8u5CYonJpDC"},"outputs":[],"source":["from shutil import copyfile, copytree, move\n","from tqdm import tqdm\n","import cv2\n","import os\n","import os.path as osp\n","import pandas as pd\n","import numpy as np\n","\n","def log(texto,titulo):\n","\n","    #print(texto)\n","    with open(titulo+'.txt',\"a\") as txt:\n","        txt.write(texto + '\\n')"]},{"cell_type":"markdown","source":["### Instalação do RetinaFace"],"metadata":{"id":"KeBvkMxRJG9S"}},{"cell_type":"markdown","source":["O RetinaFace é o detector de faces proposto por DENG et al. (2020), no trabalho \"RetinaFace: Single-Shot Multi-Level Face Localisation in the Wild\" (disponível em https://arxiv.org/abs/1905.00641)\n","\n","O modelo é encontrado no github do projeto InsightFace: https://github.com/deepinsight/insightface/tree/master/detection/retinaface"],"metadata":{"id":"F2vAMRyj8i35"}},{"cell_type":"code","source":["## Download do modelo\n","\n","# a versão do RetinaFace utilizada está no Google Drive do projeto InsightFace,\n","# portanto, utilizou-se a biblioteca gdown para o seu download\n","import gdown\n","\n","original_url = 'https://drive.google.com/file/d/1wm-6K688HQEx_H90UdAIuKv-NAsKBu85/view?usp=sharing'\n","\n","# url ajustada para a função do gdown (substitui) \n","url_id = original_url.split('/d/')[-1].split('/')[0]\n","url = 'https://drive.google.com/uc?id='+url_id\n","\n","# nome do arquivo a ser salvo\n","output = 'retinaface-R50.zip'\n","\n","#download\n","gdown.download(url, output, quiet=False)\n","\n","#instalação das bibliotecas\n","!pip install mxnet --quiet\n","!pip install insightface==0.1.5 --quiet\n","\n","#criando o diretório para o modelo encontrado no Google Drive\n","!mkdir /root/.insightface\n","!mkdir /root/.insightface/models\n","!mkdir /root/.insightface/models/retinaface_r50_v1\n","\n","#descompactando arquivo do modelo\n","!unzip -q retinaface-R50.zip -d /root/.insightface/models/retinaface_r50_v1/\n","\n","#AJUSTE DOS ARQUIVOS DO PACKAGE\n","package_path = '/usr/local/lib/python3.7/dist-packages/insightface/model_zoo'\n","\n","import os\n","import os.path as osp\n","\n","txt=\"\"\n","#--Ajustando arquivo model_zoo.py\n","fname='model_zoo.py'\n","with open(osp.join(package_path,fname),'rt') as f:\n","  txt = f.read().replace(\"from .face\",\"from insightface.model_zoo.face\")\n","\n","with open(osp.join(package_path,fname),'wt') as f:\n","  f.write(txt)\n","\n","#--Ajustando arquivo face_detection.py\n","fname='face_detection.py'\n","with open(osp.join(package_path,fname),'rt') as f:\n","  txt = f.read().replace(\"network=='net5'\",\"self.rac=='net5'\").replace(\"from .model_store\",\"from insightface.model_zoo.model_store\")\n","\n","with open(osp.join(package_path,fname),'wt') as f:\n","  f.write(txt)\n","\n","#--Ajustando arquivo model_store.py\n","fname='model_store.py'\n","with open(osp.join(package_path,fname),'rt') as f:\n","  txt = f.read().replace(\"from ..utils import download, check_sha1\",\"from insightface.utils.download import *\") \n","\n","with open(osp.join(package_path,fname),'wt') as f:\n","  f.write(txt)\n","\n","#Instanciando um modelo Retinaface\n","import insightface\n","retinaface = insightface.model_zoo.get_model('retinaface_r50_v1')\n","retinaface.prepare(ctx_id = -1) \n","\n","\n","#funcao de deteccao\n","def face_detection(image_path,model):\n","\n","    img = cv2.imread(image_path)\n","    img = cv2.resize(img,(600,600))   \n","\n","\n","    box, landmarks = model.detect(img)\n","    box = box[0]\n","\n","    x = abs(int(box[0]))\n","    y = abs(int(box[1]))\n","    w = abs(int(box[2])) - x\n","    h = abs(int(box[3])) - y\n","\n","    face = img[y:y+h,x:x+w]\n","    new_landmarks=[]\n","    for a,b in landmarks[0]:\n","        x_new = a - x\n","        y_new = b - y \n","        new_landmarks.append([x_new,y_new])\n","\n","    return face, np.array(new_landmarks,dtype='float32')\n","\n","\n"],"metadata":{"id":"XV-AW4a7JTY5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Detecção de Faces"],"metadata":{"id":"jrnsz9m2LXar"}},{"cell_type":"markdown","source":["As faces devem se encontrar na posição vertical antes da aplicação do RetinaFace"],"metadata":{"id":"s37PWCJizYaB"}},{"cell_type":"code","source":["#Detecção Faces\n","\n","path = 'diretorio das imagens originais'\n","path_new = 'diretorio no qual as imagens de face serão gravadas'\n","\n","\n","c_no_faces=0\n","for imagem in os.listdir(path):\n","  \n","  try:\n","    face, _ = face_detection(os.path.join(path,imagem),retinaface)\n","    cv2.imwrite(os.path.join(path_new,imagem),face)\n","        \n","  except Exception:\n","    print('Nao foi possivel detectar faces na imagem {}'.format(imagem))\n","    c_no_faces+=1\n","    pass\n","    \n","c_total = len(os.listdir(path))\n","\n","log(\"Total de imagens na base: \"+str(c_total),log_name)\n","log(\"Total de imagens perdidas: \"+str(c_no_faces),log_name)"],"metadata":{"id":"98Ja-3EkLaBX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Leave-some-subjects-out"],"metadata":{"id":"ldzGSUAgeNx4"}},{"cell_type":"markdown","source":["Nesta seção, será apresentada o método de divisão dos dados denominado *leave-some-subjects-out*. Trata-se do método de validação cruzada *k-fold* aplicado aos indivíduos (*subjects*) da base de dados, e não diretamente às amostras."],"metadata":{"id":"wX7G24gROawV"}},{"cell_type":"markdown","source":["O trabalho em questão utilizou a união de duas bases de dados distintas.\n","Antes da execução do script a seguir, as imagens de cada base foram organizadas em pastas de acordo com o indivíduo da amostra.\n","\n","Por exemplo:\n","\n","*   Base A\n","  *   ID_01\n","      * ID01_imagem_1\n","      * ID01_imagem_2\n","      * ...\n","      * ID01_imagem_*N*\n","\n","  * ID_02\n","  * ID_03\n","  * ...\n","  * ID_*N*\n","\n","*   Base B\n"],"metadata":{"id":"UexoiWNbgUcI"}},{"cell_type":"code","source":["cope_path='diretorio da base iCOPE'\n","unifesp_path='diretorio da base UNIFESP'\n","\n","# Subjects da base iCOPE\n","cope_nbs = os.listdir(cope_path)\n","# quantidade de subjects iCOPE\n","print(\"Subjects iCOPE: \",len(cope_nbs))\n","\n","# Subjects da base UNIFESP\n","unifesp_nbs = os.listdir(unifesp_path)\n","# quantidade de subjects UNIFESP\n","print(\"Subjects UNIFESP: \",len(unifesp_nbs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fP22LF71lVIZ","executionInfo":{"status":"ok","timestamp":1673119911763,"user_tz":180,"elapsed":5,"user":{"displayName":"Gabriel Coutrin","userId":"11379291937407237004"}},"outputId":"24a5c66c-5f7b-4b73-8561-c44c8c1db4ef"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Subjects iCOPE:  26\n","Subjects UNIFESP:  30\n"]}]},{"cell_type":"code","source":["# criação de uma lista com os \"rótulos\" dos subjects ('C' p/ iCOPE e 'U' p/ UNIFESP)\n","labels = len(cope_nbs)*['C'] + len(unifesp_nbs)*['U']\n","\n","# 26 Cs + 30 Us = 56 rótulos\n","print(\"Total de rótulos: \",len(labels))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K8KGbAKQo0TW","executionInfo":{"status":"ok","timestamp":1673119935509,"user_tz":180,"elapsed":240,"user":{"displayName":"Gabriel Coutrin","userId":"11379291937407237004"}},"outputId":"3f827673-71a3-4295-d864-71bbd8eda5bd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de rótulos:  56\n"]}]},{"cell_type":"code","source":["# lista com todos os subjects\n","nbs = cope_nbs + unifesp_nbs\n","\n","# 26 subjects iCOPE + 30 subjects UNIFESP = 56 subjects\n","print(\"Total de subjects: \",len(nbs))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eF6d03zFpG6w","executionInfo":{"status":"ok","timestamp":1673119947865,"user_tz":180,"elapsed":248,"user":{"displayName":"Gabriel Coutrin","userId":"11379291937407237004"}},"outputId":"907c0320-b4c9-49ce-ed5d-192155866a22"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Total de subjects:  56\n"]}]},{"cell_type":"markdown","source":["A função *StratifiedKFold* do módulo *sklearn* realiza a divisão *k-fold* balanceando dentro de cada *fold*. Em outras palavras, os *folds* possuem aproximadamente a mesma quantidade de imagens de cada classe. No contexto deste trabalho, a classe corresponde à base de dados de origem do *subject*."],"metadata":{"id":"abxT_igxkvPz"}},{"cell_type":"code","source":["from sklearn.model_selection import StratifiedKFold"],"metadata":{"id":"j26gPQPzp3V4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# configurando o StratifiedKFold para realizar um k-fold com k=10\n","skf = StratifiedKFold(n_splits=10)\n","\n","# conversão das listas de subjects e rótulos em numpy arrays\n","nbs = np.array(nbs)\n","labels = np.array(labels)\n","\n","# listas para coleta dos subjects (nbs, de newborns) e rótulos de treinamento\n","treino_nbs=[]\n","treino_lbs=[]\n","\n","# listas para coleta dos subjects (nbs, de newborns) e rótulos de teste\n","teste_nbs=[]\n","teste_lbs=[]\n","\n","\n","# A função StratifiedKFold retorna os índices para divisão dos vetores fornecidos\n","for train_index, test_index in skf.split(nbs, labels):\n","  treino_nbs.append(nbs[train_index])\n","  teste_nbs.append(nbs[test_index])\n","  treino_lbs.append(labels[train_index])\n","  teste_lbs.append(labels[test_index])"],"metadata":{"id":"mL_T-vubqDXI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Divisão dos 56 subjects por iteração da validação cruzada\\n\")\n","c=0\n","for bb_treino, bb_teste, lb_treino, lb_teste in zip(treino_nbs, teste_nbs, treino_lbs, teste_lbs):\n","\n","  print(\"Fold \" + str(c) + \" -- Treinamento: \" + str(len(bb_treino)) + \" Teste: \" + str(len(bb_teste)))\n","  c+=1\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TDDMH_Vms1sR","executionInfo":{"status":"ok","timestamp":1673120597172,"user_tz":180,"elapsed":5,"user":{"displayName":"Gabriel Coutrin","userId":"11379291937407237004"}},"outputId":"c05616fd-3a6f-4780-f9c4-2be6ef947b6b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Divisão dos 56 subjects por iteração da validação cruzada\n","\n","Fold 0 -- Treinamento: 50 Teste: 6\n","Fold 1 -- Treinamento: 50 Teste: 6\n","Fold 2 -- Treinamento: 50 Teste: 6\n","Fold 3 -- Treinamento: 50 Teste: 6\n","Fold 4 -- Treinamento: 50 Teste: 6\n","Fold 5 -- Treinamento: 50 Teste: 6\n","Fold 6 -- Treinamento: 51 Teste: 5\n","Fold 7 -- Treinamento: 51 Teste: 5\n","Fold 8 -- Treinamento: 51 Teste: 5\n","Fold 9 -- Treinamento: 51 Teste: 5\n"]}]},{"cell_type":"code","source":["print(\"Composição dos conjuntos de teste\\n\")\n","n=0\n","for lb_teste in teste_lbs:\n","  c = lb_teste.tolist().count('C')\n","  u = lb_teste.tolist().count('U')\n","\n","  print(\"Fold \" + str(n) + \" -- Subjects iCOPE: \" + str(c) + \" || Subjects UNIFESP: \" + str(u))\n","  n+=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PynMktOpu8J8","executionInfo":{"status":"ok","timestamp":1673120609129,"user_tz":180,"elapsed":295,"user":{"displayName":"Gabriel Coutrin","userId":"11379291937407237004"}},"outputId":"bb60f833-ce6f-46c3-807b-18e4e212bd90"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Composição dos conjuntos de teste\n","\n","Fold 0 -- Subjects iCOPE: 3 || Subjects UNIFESP: 3\n","Fold 1 -- Subjects iCOPE: 3 || Subjects UNIFESP: 3\n","Fold 2 -- Subjects iCOPE: 3 || Subjects UNIFESP: 3\n","Fold 3 -- Subjects iCOPE: 3 || Subjects UNIFESP: 3\n","Fold 4 -- Subjects iCOPE: 3 || Subjects UNIFESP: 3\n","Fold 5 -- Subjects iCOPE: 3 || Subjects UNIFESP: 3\n","Fold 6 -- Subjects iCOPE: 2 || Subjects UNIFESP: 3\n","Fold 7 -- Subjects iCOPE: 2 || Subjects UNIFESP: 3\n","Fold 8 -- Subjects iCOPE: 2 || Subjects UNIFESP: 3\n","Fold 9 -- Subjects iCOPE: 2 || Subjects UNIFESP: 3\n"]}]},{"cell_type":"code","source":["print(\"Composição dos conjuntos de treinamento\\n\")\n","n=0\n","for lb_treino in treino_lbs:\n","  c = lb_treino.tolist().count('C')\n","  u = lb_treino.tolist().count('U')\n","\n","  print(\"Fold \" + str(n) + \" -- Subjects iCOPE: \" + str(c) + \" || Subjects UNIFESP: \" + str(u))\n","  n+=1"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pWIRDG2gwry4","executionInfo":{"status":"ok","timestamp":1673120655716,"user_tz":180,"elapsed":233,"user":{"displayName":"Gabriel Coutrin","userId":"11379291937407237004"}},"outputId":"153632ea-64bb-4ae0-fca6-3ad1fc2d6aba"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Composição dos conjuntos de treinamento\n","\n","Fold 0 -- Subjects iCOPE: 23 || Subjects UNIFESP: 27\n","Fold 1 -- Subjects iCOPE: 23 || Subjects UNIFESP: 27\n","Fold 2 -- Subjects iCOPE: 23 || Subjects UNIFESP: 27\n","Fold 3 -- Subjects iCOPE: 23 || Subjects UNIFESP: 27\n","Fold 4 -- Subjects iCOPE: 23 || Subjects UNIFESP: 27\n","Fold 5 -- Subjects iCOPE: 23 || Subjects UNIFESP: 27\n","Fold 6 -- Subjects iCOPE: 24 || Subjects UNIFESP: 27\n","Fold 7 -- Subjects iCOPE: 24 || Subjects UNIFESP: 27\n","Fold 8 -- Subjects iCOPE: 24 || Subjects UNIFESP: 27\n","Fold 9 -- Subjects iCOPE: 24 || Subjects UNIFESP: 27\n"]}]},{"cell_type":"code","source":["# Salvando as listas com os conjuntos de treinamento e teste por iteração da\n","# validação cruzada. Os arquivos .npy gerados serão utilizados no script de \n","# treinamento e validação dos modelos\n","\n","treino_final = np.array(treino_nbs,dtype=object)\n","teste_final = np.array(teste_nbs,dtype=object)\n","\n","np.save('NB_KFold10_Train.npy',treino_final)\n","np.save('NB_KFold10_Test.npy',teste_final)"],"metadata":{"id":"9YJieWUSu1E8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Augmentation + RetinaFace"],"metadata":{"id":"qAycMTfie1_q"}},{"cell_type":"markdown","source":["Esta seção apresenta a geração de novas imagens para treinamento, por meio do Data Augmentation, e a validação dessas novas amostras pelo RetinaFace, com o objetivo de garantir a utilização exemplos nos quais a face humana é detectável."],"metadata":{"id":"UTyHJ91W0Yui"}},{"cell_type":"markdown","source":["### Data Augmentation"],"metadata":{"id":"feIn7jLp8ClY"}},{"cell_type":"code","source":["# Configurando gerador de novas amostras\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.preprocessing.image import load_img, img_to_array\n","\n","datagen = ImageDataGenerator(rotation_range=30, \n","                             shear_range=0.15,\n","                             width_shift_range=0.2,\n","                             height_shift_range=0.2,\n","                             brightness_range=(0.5, 1.1),\n","                             zoom_range=[0.7, 1.5],\n","                             horizontal_flip=True)"],"metadata":{"id":"bLrIxeVffbll"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Antes da execução do script a seguir, as imagens de cada base foram organizadas em pastas de acordo com o indivíduo da amostra.\n","\n","Por exemplo:\n","\n","*   Base A\n","  *   ID_01\n","      * ID01_imagem_1\n","      * ID01_imagem_2\n","      * ...\n","      * ID01_imagem_*N*\n","\n","  * ID_02\n","  * ID_03\n","  * ...\n","  * ID_*N*\n","\n","*   Base B"],"metadata":{"id":"4xsTPUtV49Ug"}},{"cell_type":"code","source":["# Diretórios\n","\n","dir_base = 'diretório das base de dados original'\n","dir_base_aug = 'diretório destino da base aumentada'\n","\n","# criação de pastas para organizar as novas amostras por subject da base\n","for fold in os.listdir(dir_base):\n","  aug_dir = osp.join(dir_base_aug, fold + \"_aug\")\n","  os.mkdir(aug_dir)\n"],"metadata":{"id":"wEp3WrxAgb3q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Geração de novas amostras\n","\n","NUM_DATAGEN=20  # 20 novas amostras a partir de uma imagem\n","\n","# -- Data Augmentation -- #\n","\n","dir_base = 'diretório das base de dados original'\n","dir_base_aug = 'diretório destino da base aumentada'\n","\n","# varrendo indivíduos da base\n","for fold in tqdm(os.listdir(dir_base)):\n","\n","  # varrendo imagens do indivíduo\n","  for img in os.listdir(osp.join(dir_base,fold)):\n","\n","    # endereço da imagem\n","    img_path = osp.join(dir_base,fold,img)\n","\n","    # carregando imagem\n","    image = load_img(img_path)\n","    image = img_to_array(image)\n","    image = np.expand_dims(image, axis=0)\n","\n","    # enderço destino das novas amostras\n","    new_path = osp.join(dir_base_aug, fold + \"_aug\")\n","\n","    # preparação do gerador de imagens\n","    datagen.fit(image)\n","\n","    # prefixo para o nome das novas amotras\n","    prefix = 'aug_'+img.split('.png')[0]\n","\n","    # geração das novas amostras\n","    for x, val in zip(datagen.flow(image, save_to_dir=new_path,\n","                                        save_prefix=prefix, save_format='png'),range(NUM_DATAGEN)):     \n","      pass\n","\n","print(\"FIM!\")"],"metadata":{"id":"I_MScNXqfyPj"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Validação - Detecção de faces"],"metadata":{"id":"RPBdZLUS8zDn"}},{"cell_type":"code","source":["#Validacao RetinaFace\n","\n","dir_base_aug = 'diretório da base aumentada'\n","c_faces=0\n","c_nofaces=0\n","\n","# varrendo indivíduos da base\n","for fold in tqdm(os.listdir(dir_base_aug)):\n","\n","  # varrendo imagens \"aumentadas\" do indivíduo\n","  for img in os.listdir(osp.join(dir_base_aug,fold)):\n","\n","    # endereço da imagem\n","    file_path = osp.join(dir_base_aug,fold,img)\n","\n","    # tentativa de detecção facial\n","    try:\n","        face, _ = face_detection(file_path,retinaface)\n","        c_faces+=1\n","\n","    # caso não a face não seja encontrada, \n","    # a amostra gerada por Data Augmentation é deletada    \n","    except:\n","        os.remove(file_path)\n","        c_nofaces+=1\n","        pass\n","\n","print(\"\\nImagens aprovadas: \",c_faces)\n","print(\"Imagens rejeitas: \",c_nofaces)\n","print(\"Total: \", c_faces + c_nofaces)\n","print(\"-------------------------\")"],"metadata":{"id":"viHPTfsGgGlh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Divisão \"Dor\" e \"Sem_dor\""],"metadata":{"id":"MohxYAbrXEzM"}},{"cell_type":"markdown","source":["Para a execução da rotina de treinamento e validação dos modelos (apresentada no arquivo Treinamento.ipynb), a base de dados original e a base de dados aumentada devem estar organizadas por indivíduo, e as imagens de cada indívudo devem ser separadas em \"Dor\" e \"Sem Dor\":\n","\n","> \n","*   Base A\n","  *   ID_01\n","      * Dor\n","          * ID01_imagem_dor_1\n","          * ID01_imagem_dor_2\n","          * ...\n","          * ID01_imagem_dor_*N*\n","      * Sem Dor\n","          * ID01_imagem_semdor_1\n","          * ID01_imagem_semdor_2\n","          * ...\n","          * ID01_imagem_semdor_*N*\n","  * ID_02\n","      *  Dor\n","      *  Sem Dor\n","  * ID_03\n","  * ...\n","  * ID_*N*\n","*   Base B"],"metadata":{"id":"gfWEJby4CTdT"}},{"cell_type":"code","source":["# Criação de diretórios conforme a organização apresentada anteriormente\n","\n","\n","# Base Original\n","path = 'diretorio da base original, separada por indivíduos'\n","path2 ='um novo diretorio para receber a base original, conforme a nova organização'\n","\n","# varrendo indivíduos da base original\n","for fold in os.listdir(path):\n","  # pasta para indivíduo no novo endereço\n","  new_path = osp.join(path2,fold)\n","\n","  # pasta \"Dor\" para o indivíduo no novo endereço\n","  new_path_dor = osp.join(new_path,\"Dor\")\n","\n","  # pasta \"Sem Dor\" para o indivíduo no novo endereço\n","  new_path_sem_dor = osp.join(new_path,\"Sem_dor\")\n","\n","  # criação das pastas\n","  os.mkdir(new_path)\n","  os.mkdir(new_path_dor)\n","  os.mkdir(new_path_sem_dor)\n","\n","\n","# Base Aumentada\n","path = 'diretorio da base aumentada, separada por indivíduos'\n","path2 ='um novo diretorio para receber a base aumentada, conforme a nova organização'\n","\n","# varrendo indivíduos da base aumentada\n","for fold in os.listdir(path):\n","  # pasta para indivíduo no novo endereço\n","  new_path = osp.join(path2,fold)\n","\n","  # pasta \"Dor\" para o indivíduo no novo endereço\n","  new_path_dor = osp.join(new_path,\"Dor\")\n","\n","  # pasta \"Sem Dor\" para o indivíduo no novo endereço\n","  new_path_sem_dor = osp.join(new_path,\"Sem_dor\")\n","\n","  # criação das pastas\n","  os.mkdir(new_path)\n","  os.mkdir(new_path_dor)\n","  os.mkdir(new_path_sem_dor)"],"metadata":{"id":"r_KOCp9_gU7y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Cópia das imagens para as novas pastas\n","\n","## Base Original ##\n","path1 = 'diretorio da base original, separada por indivíduos'\n","path2 ='um novo diretorio para receber a base original, conforme a nova organização'\n","\n","# varrendo indivíduos da base\n","for fold in os.listdir(path1):\n","\n","  # varrendo imagens do indivíduo\n","  for img in os.listdir(osp.join(path1,fold)):\n","\n","    # endereço de origem da imagem\n","    path_src = osp.join(path1,fold,img)\n","\n","    # determinação da classe a partir do nome da imagem\n","    classe = \"Sem_dor\" if \"sem_dor\" in img else \"Dor\n","\n","    # endereço destino da imagem, considerando sua classe\n","    path_dest = osp.join(path2,fold,classe,img)\n","\n","    # cópia da imagem no novo endereço\n","    copyfile(path_src,path_dest)\n","\n","## Base Aumentada ##\n","path1 = 'diretorio da base aumentada, separada por indivíduos'\n","path2 ='um novo diretorio para receber a base aumentada, conforme a nova organização'\n","\n","# varrendo indivíduos da base\n","for fold in os.listdir(path1):\n","\n","  # varrendo imagens do indivíduo\n","  for img in os.listdir(osp.join(path1,fold)):\n","\n","    # endereço de origem da imagem\n","    path_src = osp.join(path1,fold,img)\n","\n","    # determinação da classe a partir do nome da imagem\n","    classe = \"Sem_dor\" if \"sem_dor\" in img else \"Dor\n","\n","    # endereço destino da imagem, considerando sua classe\n","    path_dest = osp.join(path2,fold,classe,img)\n","\n","    # cópia da imagem no novo endereço\n","    copyfile(path_src,path_dest)"],"metadata":{"id":"S1qDWLTZsYmL"},"execution_count":null,"outputs":[]}]}